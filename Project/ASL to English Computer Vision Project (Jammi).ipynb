{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e39099c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "##all nessecary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c10359a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so with the size - C T H W -> 512\n",
    "#with a bigger size, I wanted to see if it would give a higher accuracy maybe?\n",
    "#more information -> comparative to ayush's work\n",
    "class ASLModel(nn.Module):\n",
    "    def __init__(self, words = 340, frames = 60, size = 512):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(3, 16, 3, padding = \"same\")\n",
    "        self.conv2 = nn.Conv3d(16, 16, 3, padding = \"same\")\n",
    "        self.conv3 = nn.Conv3d(16, 32, 3, padding = \"same\")\n",
    "        self.conv4 = nn.Conv3d(32, 32, 3, padding = \"same\")\n",
    "        self.conv5 = nn.Conv3d(32, 64, 3, padding = \"same\")\n",
    "        self.conv6 = nn.Conv3d(64,64,3, padding = \"same\")\n",
    "        self.conv7 = nn.Conv3d(64, 128, 3, padding = \"same\")\n",
    "        self.conv8 = nn.Conv3d(128, 128, 3, padding = \"same\")\n",
    "        self.conv9 = nn.Conv3d(128, 256, 3, padding = \"same\")\n",
    "        self.conv10 = nn.Conv3d(256, 256, 3, padding = \"same\")\n",
    "        self.conv11 = nn.Conv3d(256, 512, 3, padding = \"same\")\n",
    "        #idk if i did this next part right\n",
    "        self.mp1 = nn.MaxPool3d((1,2,2))\n",
    "        self.mp2 = nn.MaxPool3d(2)\n",
    "        self.relu = nn.RELU() #???\n",
    "        #im giving this the same var as ayush the goat\n",
    "        self.preds1 = nn.Linear(int(512*(frames/2)*(size/64)*(size/64)), words)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.mp1(self.relu(self.conv2(x)))\n",
    "        tmp = x\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.rely(self.conv4)\n",
    "        x = tmp + x\n",
    "        x = self.mp1(self.relu(self.conv5(x))) # 64\n",
    "        tmp = x\n",
    "        x = self.relu(self.conv6(x))\n",
    "        x = self.relu(self.conv7(x))\n",
    "        x = self.relu(self.conv8(x))\n",
    "        x = tmp + x \n",
    "        x = self.mp1(x) #128\n",
    "        tmp = x\n",
    "        x = self.relu(self.conv9(x))\n",
    "        x = self.rely(self.conv10(x))\n",
    "        x = tmp + x\n",
    "        x = self.mp2(x)\n",
    "        x = tmp \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.preds1(x)) # im like 73% sure this is right\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4df47ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0.6187, 0.5525, 0.3523,  ..., 0.1103, 0.5558, 0.8668],\n",
       "           [0.3274, 0.9758, 0.3533,  ..., 0.8725, 0.3374, 0.6668],\n",
       "           [0.2020, 0.9394, 0.5842,  ..., 0.6396, 0.9570, 0.6787],\n",
       "           ...,\n",
       "           [0.6392, 0.7153, 0.8598,  ..., 0.7122, 0.7741, 0.0293],\n",
       "           [0.3393, 0.7929, 0.1579,  ..., 0.9628, 0.4880, 0.7131],\n",
       "           [0.6289, 0.0556, 0.9133,  ..., 0.9534, 0.8833, 0.2205]],\n",
       "\n",
       "          [[0.4334, 0.3887, 0.6413,  ..., 0.1377, 0.3233, 0.7196],\n",
       "           [0.2513, 0.5996, 0.4922,  ..., 0.4666, 0.1227, 0.4636],\n",
       "           [0.4753, 0.4693, 0.6577,  ..., 0.9315, 0.9425, 0.3322],\n",
       "           ...,\n",
       "           [0.0834, 0.7390, 0.0121,  ..., 0.1005, 0.9696, 0.5409],\n",
       "           [0.8780, 0.8146, 0.4373,  ..., 0.3865, 0.4291, 0.6364],\n",
       "           [0.1354, 0.9959, 0.8372,  ..., 0.1765, 0.4236, 0.6607]],\n",
       "\n",
       "          [[0.4728, 0.7211, 0.5251,  ..., 0.1082, 0.7495, 0.0208],\n",
       "           [0.9386, 0.9635, 0.7485,  ..., 0.5173, 0.0939, 0.2351],\n",
       "           [0.8034, 0.4663, 0.7148,  ..., 0.9804, 0.0544, 0.3437],\n",
       "           ...,\n",
       "           [0.3657, 0.2458, 0.5074,  ..., 0.7358, 0.8143, 0.9256],\n",
       "           [0.6690, 0.0282, 0.9916,  ..., 0.4866, 0.1220, 0.2489],\n",
       "           [0.2596, 0.3433, 0.2371,  ..., 0.9516, 0.7180, 0.8675]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0.2947, 0.4035, 0.5642,  ..., 0.4453, 0.9692, 0.0515],\n",
       "           [0.9386, 0.3847, 0.1127,  ..., 0.7067, 0.8963, 0.1735],\n",
       "           [0.2525, 0.0192, 0.7831,  ..., 0.3754, 0.5764, 0.8174],\n",
       "           ...,\n",
       "           [0.5966, 0.9703, 0.2134,  ..., 0.6697, 0.5755, 0.3600],\n",
       "           [0.7939, 0.5430, 0.1658,  ..., 0.9403, 0.5917, 0.2006],\n",
       "           [0.5667, 0.2484, 0.0796,  ..., 0.5291, 0.2812, 0.7247]],\n",
       "\n",
       "          [[0.4970, 0.7905, 0.8048,  ..., 0.9329, 0.0167, 0.0223],\n",
       "           [0.8482, 0.2457, 0.9442,  ..., 0.5578, 0.0504, 0.4939],\n",
       "           [0.1686, 0.9278, 0.6012,  ..., 0.4278, 0.7215, 0.8956],\n",
       "           ...,\n",
       "           [0.1376, 0.7990, 0.0653,  ..., 0.8527, 0.9056, 0.0383],\n",
       "           [0.7468, 0.5622, 0.1330,  ..., 0.4643, 0.6751, 0.8160],\n",
       "           [0.3815, 0.1536, 0.2465,  ..., 0.7315, 0.1638, 0.8891]],\n",
       "\n",
       "          [[0.8653, 0.2363, 0.0988,  ..., 0.6569, 0.1187, 0.1259],\n",
       "           [0.5289, 0.1267, 0.6375,  ..., 0.7011, 0.7406, 0.9482],\n",
       "           [0.3483, 0.3379, 0.4094,  ..., 0.2758, 0.1529, 0.6391],\n",
       "           ...,\n",
       "           [0.0301, 0.2468, 0.7125,  ..., 0.6151, 0.8814, 0.8124],\n",
       "           [0.8341, 0.0442, 0.4855,  ..., 0.9134, 0.1083, 0.4140],\n",
       "           [0.1628, 0.3245, 0.3114,  ..., 0.3161, 0.2831, 0.9006]]],\n",
       "\n",
       "\n",
       "         [[[0.4924, 0.7277, 0.0494,  ..., 0.6604, 0.1613, 0.6806],\n",
       "           [0.7751, 0.0841, 0.0828,  ..., 0.1289, 0.9241, 0.0135],\n",
       "           [0.5213, 0.2248, 0.5224,  ..., 0.0644, 0.4115, 0.1097],\n",
       "           ...,\n",
       "           [0.4743, 0.1200, 0.8972,  ..., 0.3826, 0.8344, 0.4863],\n",
       "           [0.0408, 0.2927, 0.4174,  ..., 0.2190, 0.7041, 0.1756],\n",
       "           [0.6543, 0.4632, 0.8550,  ..., 0.7810, 0.5232, 0.7425]],\n",
       "\n",
       "          [[0.7348, 0.9870, 0.3439,  ..., 0.6580, 0.1390, 0.9058],\n",
       "           [0.2676, 0.5281, 0.6588,  ..., 0.1162, 0.3967, 0.9275],\n",
       "           [0.5339, 0.7134, 0.7121,  ..., 0.3302, 0.4969, 0.4032],\n",
       "           ...,\n",
       "           [0.7312, 0.9205, 0.6607,  ..., 0.0637, 0.2319, 0.3539],\n",
       "           [0.3136, 0.5944, 0.8560,  ..., 0.5777, 0.9019, 0.8005],\n",
       "           [0.7860, 0.3447, 0.5722,  ..., 0.0676, 0.3094, 0.0877]],\n",
       "\n",
       "          [[0.2411, 0.5425, 0.4305,  ..., 0.7764, 0.5445, 0.9995],\n",
       "           [0.6449, 0.7227, 0.2093,  ..., 0.1381, 0.1812, 0.7623],\n",
       "           [0.4425, 0.8061, 0.0635,  ..., 0.2417, 0.0576, 0.5311],\n",
       "           ...,\n",
       "           [0.3120, 0.1137, 0.1961,  ..., 0.0876, 0.3250, 0.1602],\n",
       "           [0.8163, 0.3222, 0.7070,  ..., 0.8485, 0.1255, 0.7885],\n",
       "           [0.3334, 0.6627, 0.0896,  ..., 0.0674, 0.6431, 0.8558]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0.7838, 0.3814, 0.7601,  ..., 0.6219, 0.3329, 0.4625],\n",
       "           [0.5581, 0.7053, 0.0520,  ..., 0.4486, 0.9633, 0.1431],\n",
       "           [0.3076, 0.7450, 0.8645,  ..., 0.3136, 0.1282, 0.4703],\n",
       "           ...,\n",
       "           [0.6395, 0.6147, 0.8438,  ..., 0.5097, 0.7514, 0.7852],\n",
       "           [0.3002, 0.7487, 0.9770,  ..., 0.3937, 0.1222, 0.4741],\n",
       "           [0.2149, 0.8332, 0.9037,  ..., 0.3880, 0.0077, 0.1523]],\n",
       "\n",
       "          [[0.4415, 0.9078, 0.4930,  ..., 0.8929, 0.7653, 0.9426],\n",
       "           [0.5843, 0.1061, 0.2031,  ..., 0.3524, 0.5231, 0.4098],\n",
       "           [0.9924, 0.2514, 0.2112,  ..., 0.1144, 0.8812, 0.4590],\n",
       "           ...,\n",
       "           [0.3178, 0.2559, 0.9131,  ..., 0.2005, 0.3457, 0.9804],\n",
       "           [0.0323, 0.2425, 0.3837,  ..., 0.7834, 0.3538, 0.3418],\n",
       "           [0.6282, 0.9468, 0.8973,  ..., 0.5261, 0.8119, 0.6161]],\n",
       "\n",
       "          [[0.8067, 0.4080, 0.9956,  ..., 0.9364, 0.9725, 0.0774],\n",
       "           [0.7421, 0.3518, 0.0627,  ..., 0.6431, 0.0108, 0.4327],\n",
       "           [0.1629, 0.4494, 0.1179,  ..., 0.8872, 0.9990, 0.0954],\n",
       "           ...,\n",
       "           [0.4538, 0.4680, 0.5994,  ..., 0.5064, 0.4701, 0.2739],\n",
       "           [0.5502, 0.5523, 0.3696,  ..., 0.9162, 0.2227, 0.2927],\n",
       "           [0.3053, 0.9470, 0.8366,  ..., 0.1960, 0.4027, 0.2145]]],\n",
       "\n",
       "\n",
       "         [[[0.6341, 0.6291, 0.1419,  ..., 0.6967, 0.4185, 0.4343],\n",
       "           [0.8338, 0.6658, 0.2219,  ..., 0.6300, 0.3626, 0.6785],\n",
       "           [0.5459, 0.3059, 0.4064,  ..., 0.2973, 0.5759, 0.0922],\n",
       "           ...,\n",
       "           [0.8833, 0.4228, 0.2979,  ..., 0.6412, 0.0164, 0.6419],\n",
       "           [0.4078, 0.9091, 0.5831,  ..., 0.0254, 0.4404, 0.6251],\n",
       "           [0.4871, 0.8647, 0.1184,  ..., 0.3417, 0.0867, 0.0149]],\n",
       "\n",
       "          [[0.1827, 0.6533, 0.1686,  ..., 0.7633, 0.7248, 0.3070],\n",
       "           [0.3805, 0.8485, 0.4677,  ..., 0.3086, 0.9707, 0.9991],\n",
       "           [0.4013, 0.6622, 0.6586,  ..., 0.2580, 0.9139, 0.2456],\n",
       "           ...,\n",
       "           [0.0046, 0.9348, 0.8612,  ..., 0.1235, 0.9169, 0.9920],\n",
       "           [0.1026, 0.4310, 0.8525,  ..., 0.4299, 0.0375, 0.7450],\n",
       "           [0.1674, 0.9166, 0.2401,  ..., 0.2580, 0.5896, 0.7673]],\n",
       "\n",
       "          [[0.6667, 0.7302, 0.2641,  ..., 0.9556, 0.8159, 0.8374],\n",
       "           [0.2871, 0.6929, 0.1048,  ..., 0.2025, 0.8464, 0.0683],\n",
       "           [0.0504, 0.1523, 0.7459,  ..., 0.3109, 0.6273, 0.1978],\n",
       "           ...,\n",
       "           [0.5406, 0.9921, 0.6986,  ..., 0.7315, 0.8029, 0.6822],\n",
       "           [0.5680, 0.3246, 0.3353,  ..., 0.3419, 0.8719, 0.1473],\n",
       "           [0.2059, 0.5561, 0.0259,  ..., 0.0367, 0.9070, 0.5139]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0.4861, 0.7326, 0.3539,  ..., 0.2267, 0.7338, 0.8549],\n",
       "           [0.9403, 0.2120, 0.3474,  ..., 0.5410, 0.5729, 0.8182],\n",
       "           [0.4510, 0.2955, 0.5740,  ..., 0.6419, 0.7513, 0.0902],\n",
       "           ...,\n",
       "           [0.2161, 0.2423, 0.1893,  ..., 0.7804, 0.4855, 0.9377],\n",
       "           [0.6529, 0.3201, 0.3710,  ..., 0.4180, 0.2917, 0.4470],\n",
       "           [0.7786, 0.7756, 0.7128,  ..., 0.2491, 0.9021, 0.3544]],\n",
       "\n",
       "          [[0.1172, 0.7906, 0.6157,  ..., 0.9086, 0.0395, 0.6761],\n",
       "           [0.7932, 0.0893, 0.1416,  ..., 0.0674, 0.8543, 0.4212],\n",
       "           [0.0400, 0.2209, 0.3139,  ..., 0.9246, 0.0945, 0.0488],\n",
       "           ...,\n",
       "           [0.8876, 0.8143, 0.4678,  ..., 0.3811, 0.8854, 0.4868],\n",
       "           [0.9135, 0.9014, 0.6620,  ..., 0.1818, 0.9404, 0.5406],\n",
       "           [0.0471, 0.0463, 0.4240,  ..., 0.1823, 0.3416, 0.3838]],\n",
       "\n",
       "          [[0.5700, 0.5490, 0.6403,  ..., 0.1049, 0.6664, 0.2076],\n",
       "           [0.6828, 0.0123, 0.9957,  ..., 0.8597, 0.0628, 0.4165],\n",
       "           [0.4000, 0.3667, 0.7442,  ..., 0.0872, 0.9972, 0.4352],\n",
       "           ...,\n",
       "           [0.4741, 0.0706, 0.7052,  ..., 0.9584, 0.3361, 0.0179],\n",
       "           [0.3411, 0.2371, 0.2837,  ..., 0.3549, 0.6974, 0.4835],\n",
       "           [0.2713, 0.7489, 0.0045,  ..., 0.0346, 0.6260, 0.4328]]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 3, 60, 512, 512)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a6f322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83ceae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90be28d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
