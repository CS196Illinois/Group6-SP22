{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torchvision.io import read_video\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, json, frame=60, size=256):\n",
    "        f = open(json, 'r')\n",
    "        data = json.load(f)\n",
    "        \n",
    "        self.clips = []\n",
    "        \n",
    "        self.labels = {}\n",
    "        total_classes = len(data)\n",
    "        current_class = 0\n",
    "        \n",
    "        self.frames = frame\n",
    "        self.size = size\n",
    "\n",
    "        for key in data:\n",
    "            \n",
    "            one_hot_version = torch.nn.functional.one_hot(torch.tensor([current_class]), num_classes=total_classes)\n",
    "            self.labels[key] = one_hot_version # make it the next one_hot\n",
    "            current_class += 1\n",
    "            \n",
    "            for value in data[key]:\n",
    "                self.clips.append((key, value))\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.clips)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        word, video_data = self.clips[idx]\n",
    "        # convert the word to a one hot encoding\n",
    "        label = self.labels[word]\n",
    "        \n",
    "        # convert the video data to be the same shape (and load the video)\n",
    "        frame_start, frame_end, video_url = video_data\n",
    "        # get the video path\n",
    "        video_path = \"videos/\"+ \"_\".join(video_url.split('/')[-2:]).split('.')[0] + \".mp4\"\n",
    "        # load the video\n",
    "        r = read_video(video_path)\n",
    "        # slice the video\n",
    "        r = r[frame_start:frame_end]\n",
    "        # t, h, w, c\n",
    "        # c, t, h, w\n",
    "        r = r.permute([3, 0, 1, 2]) \n",
    "        # specified frames and size beforehand\n",
    "        # resize the video H = 480, W = 640\n",
    "        hstart = (480 - self.size)/2\n",
    "        wstart = (640 - self.size)/2\n",
    "        r = r[:][:][hstart:hstart+self.size][wstart:wstart+self.size]\n",
    "        # shorten/length the video\n",
    "        t = r.shape[1] #time of video\n",
    "        if (t < self.frames): #if shorter, repeats frames\n",
    "            tmp = torch.full((self.frames, r.shape[2], r.shape[3], r.shape[0]), 0)\n",
    "            tmp = tmp.permute([3, 0, 1, 2])\n",
    "            for i in range(self.frames / t):\n",
    "                tmp[:][i*t:i*t+t] = r\n",
    "            tmp[:][-(self.frames % t):] = r[:][:(self.frames%t)]\n",
    "            r = tmp\n",
    "        if (t > self.frames): # if longer, shortens to middle frames\n",
    "            timestart = (t - self.frames)/2\n",
    "            #alternate\n",
    "            #timestart = torch.randint(0, t - self.frames)\n",
    "            r = r[:][timestart:timestart+self.frames]\n",
    "        return r, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f89f0f655ba6204e4462aa21bff0896cc3af33d9ffa34432aa3937069c79038e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
