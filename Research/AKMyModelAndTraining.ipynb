{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "RN9P5GtLh-Kx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "3uYzvYMjiPkF"
      },
      "outputs": [],
      "source": [
        "#Tools Conv3D, MaxPool3D, relu, flatten, softmax\n",
        "# in_channels = 3, 128x128\n",
        "#will reside from 3, x, 640x480 in dataloader\n",
        "# 3, 60, 224, 224\n",
        "#400 total probabilities? -> even number\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_words=340, frames=60,size=256):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv3d(3, 32, 3, padding = 'same')\n",
        "        self.conv2 = nn.Conv3d(32, 32, 3, padding = 'same')\n",
        "        self.conv3 = nn.Conv3d(32, 32, 3, padding = 'same')\n",
        "        self.conv4 = nn.Conv3d(32, 32, 3, padding = 'same')\n",
        "        self.conv5 = nn.Conv3d(32, 64, 3, padding = 'same') \n",
        "\n",
        "        self.conv6 = nn.Conv3d(64, 64, 3, padding = 'same')\n",
        "        self.conv7 = nn.Conv3d(64, 64, 3, padding = 'same')\n",
        "\n",
        "        self.conv8 = nn.Conv3d(64, 128, 3, padding = 'same')\n",
        "        self.conv9 = nn.Conv3d(128, 128, 3, padding = 'same')\n",
        "        self.conv10 = nn.Conv3d(128, 128, 3, padding = 'same')\n",
        "\n",
        "        self.conv11 = nn.Conv3d(128, 128, 3, padding = 'same')\n",
        "        self.conv12 = nn.Conv3d(128, 128, 3, padding = 'same')\n",
        "        self.conv13 = nn.Conv3d(128, 128, 3, padding = 'same')\n",
        "        self.conv14 = nn.Conv3d(128, 128, 3, padding = 'same')\n",
        "        self.conv15 = nn.Conv3d(128, 128, 3, padding = 'same')\n",
        "        self.conv16 = nn.Conv3d(128, 128, 3, padding = 'same')\n",
        "        self.conv17 = nn.Conv3d(128, 256, 3, padding = 'same')\n",
        "\n",
        "        self.pool1 = nn.MaxPool3d((1, 2, 2))\n",
        "        self.pool2 = nn.MaxPool3d(2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.preds1 = nn.Linear(int(128*(frames/4)*(size/16)*(size/16)), 4096)\n",
        "        self.preds2 = nn.Linear(4096, num_words)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #C T H W = 3 self.frames self.size self.size\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        tmp = x\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.relu(self.conv4(x))\n",
        "        x = tmp + x\n",
        "        x = self.pool1(F.relu(self.conv5(x))) # 64 self.frames self.size/2 self.size/2\n",
        "        tmp = x\n",
        "        x = self.relu(self.conv6(x))\n",
        "        x = self.relu(self.conv7(x))\n",
        "        x = tmp + x \n",
        "        x = self.relu(self.conv8(x))\n",
        "        tmp = x \n",
        "        x = self.relu(self.conv9(x))\n",
        "        x = self.relu(self.conv10(x)) \n",
        "        x = tmp + x \n",
        "        x = self.pool1(x) # C T H W = 128 self.frames self.size/4 self.size/4\n",
        "        x = self.relu(self.conv11(x))\n",
        "        tmp = x\n",
        "        x = self.relu(self.conv12(x))\n",
        "        x = self.relu(self.conv13(x))\n",
        "        x = tmp + x\n",
        "        x = self.pool2(x) # 256 self.frames/2 self.size/8 self.size/8\n",
        "        tmp = x\n",
        "        x = self.relu(self.conv14(x)) \n",
        "        x = self.relu(self.conv15(x)) \n",
        "        x = tmp + x\n",
        "        x = self.pool2(x)\n",
        "        tmp = x\n",
        "        x = self.relu(self.conv16(x)) \n",
        "        x = self.relu(self.conv17(x)) \n",
        "        x = tmp + x # 256 self.frames/4 self.size/16 self.size/16\n",
        "\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = self.preds1(x)\n",
        "        x = self.preds2(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "OZIAw798vDYW"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(1, 3, 60, 256, 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "pRb-3kgrvooZ"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "[enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 8053063680 bytes.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\khota\\OneDrive\\Documents\\GitHub\\Group6-SP22\\Research\\AKMyModelAndTraining.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000003?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m Net()\n",
            "\u001b[1;32mc:\\Users\\khota\\OneDrive\\Documents\\GitHub\\Group6-SP22\\Research\\AKMyModelAndTraining.ipynb Cell 2'\u001b[0m in \u001b[0;36mNet.__init__\u001b[1;34m(self, num_words, frames, size)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000001?line=31'>32</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool2 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMaxPool3d(\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000001?line=32'>33</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mReLU()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000001?line=33'>34</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreds1 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mLinear(\u001b[39mint\u001b[39;49m(\u001b[39m128\u001b[39;49m\u001b[39m*\u001b[39;49m(frames\u001b[39m/\u001b[39;49m\u001b[39m4\u001b[39;49m)\u001b[39m*\u001b[39;49m(size\u001b[39m/\u001b[39;49m\u001b[39m16\u001b[39;49m)\u001b[39m*\u001b[39;49m(size\u001b[39m/\u001b[39;49m\u001b[39m16\u001b[39;49m)), \u001b[39m4096\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000001?line=34'>35</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreds2 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(\u001b[39m4096\u001b[39m, num_words)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\linear.py:85\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/linear.py?line=82'>83</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_features \u001b[39m=\u001b[39m in_features\n\u001b[0;32m     <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/linear.py?line=83'>84</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_features \u001b[39m=\u001b[39m out_features\n\u001b[1;32m---> <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/linear.py?line=84'>85</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty((out_features, in_features), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n\u001b[0;32m     <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/linear.py?line=85'>86</a>\u001b[0m \u001b[39mif\u001b[39;00m bias:\n\u001b[0;32m     <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/linear.py?line=86'>87</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty(out_features, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n",
            "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 8053063680 bytes."
          ]
        }
      ],
      "source": [
        "model = Net()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "E103uNnUvvr8",
        "outputId": "7b5b0a69-0f6f-4e67-edae-4b25c2972492"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "[enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 503316480 bytes.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\khota\\OneDrive\\Documents\\GitHub\\Group6-SP22\\Research\\AKMyModelAndTraining.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000004?line=0'>1</a>\u001b[0m model(x)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32mc:\\Users\\khota\\OneDrive\\Documents\\GitHub\\Group6-SP22\\Research\\AKMyModelAndTraining.ipynb Cell 2'\u001b[0m in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000001?line=42'>43</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv4(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000001?line=43'>44</a>\u001b[0m x \u001b[39m=\u001b[39m tmp \u001b[39m+\u001b[39m x\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000001?line=44'>45</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool1(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv5(x))) \u001b[39m# 64 self.frames self.size/2 self.size/2\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000001?line=45'>46</a>\u001b[0m tmp \u001b[39m=\u001b[39m x\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000001?line=46'>47</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv6(x))\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\conv.py:592\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/conv.py?line=590'>591</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/conv.py?line=591'>592</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\conv.py:587\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/conv.py?line=574'>575</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/conv.py?line=575'>576</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv3d(\n\u001b[0;32m    <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/conv.py?line=576'>577</a>\u001b[0m         F\u001b[39m.\u001b[39mpad(\n\u001b[0;32m    <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/conv.py?line=577'>578</a>\u001b[0m             \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/conv.py?line=584'>585</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups,\n\u001b[0;32m    <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/conv.py?line=585'>586</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/conv.py?line=586'>587</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv3d(\n\u001b[0;32m    <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/conv.py?line=587'>588</a>\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups\n\u001b[0;32m    <a href='file:///c%3A/Users/khota/miniconda3/envs/test/lib/site-packages/torch/nn/modules/conv.py?line=588'>589</a>\u001b[0m )\n",
            "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 503316480 bytes."
          ]
        }
      ],
      "source": [
        "model(x).cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\khota\\OneDrive\\Documents\\GitHub\\Group6-SP22\\Research\\AKMyModelAndTraining.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000005?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000005?line=3'>4</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000005?line=4'>5</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'trainloader' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\khota\\OneDrive\\Documents\\GitHub\\Group6-SP22\\Research\\AKMyModel.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModel.ipynb#ch0000009?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):  \u001b[39m# loop over the dataset multiple times\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModel.ipynb#ch0000009?line=1'>2</a>\u001b[0m     running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModel.ipynb#ch0000009?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m trainloader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModel.ipynb#ch0000009?line=3'>4</a>\u001b[0m         \u001b[39m# get the inputs; data is a list of [inputs, labels]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModel.ipynb#ch0000009?line=4'>5</a>\u001b[0m         inputs, labels \u001b[39m=\u001b[39m data\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModel.ipynb#ch0000009?line=6'>7</a>\u001b[0m         \u001b[39m# zero the parameter gradients\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'trainloader' is not defined"
          ]
        }
      ],
      "source": [
        "for epoch in range(100):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for data in trainloader:\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "print('Finished Training')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CS124H.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
