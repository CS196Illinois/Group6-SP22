{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RN9P5GtLh-Kx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3uYzvYMjiPkF"
      },
      "outputs": [],
      "source": [
        "#Tools Conv3D, MaxPool3D, relu, flatten\n",
        "# 3, frames, size, size = C T H W\n",
        "#possible changes = use pool1 more often instead of pool2\n",
        "#add other layers\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_words=340, frames=60,size=256):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv3d(3, 32, 3, padding = 'same')\n",
        "        self.conv2 = nn.Conv3d(32, 32, 3, padding = 'same')\n",
        "        self.conv3 = nn.Conv3d(32, 32, 3, padding = 'same')\n",
        "        self.conv4 = nn.Conv3d(32, 32, 3, padding = 'same')\n",
        "        self.conv5 = nn.Conv3d(32, 64, 3, padding = 'same') \n",
        "\n",
        "        self.conv6 = nn.Conv3d(64, 64, 3, padding = 'same')\n",
        "        self.conv7 = nn.Conv3d(64, 64, 3, padding = 'same')\n",
        "\n",
        "        self.conv8 = nn.Conv3d(64, 128, 3, padding = 'same')\n",
        "        self.conv9 = nn.Conv3d(128, 128, 3, padding = 'same')\n",
        "        self.conv10 = nn.Conv3d(128, 128, 3, padding = 'same')\n",
        "\n",
        "        self.conv11 = nn.Conv3d(128, 128, 3, padding = 'same')\n",
        "        self.conv12 = nn.Conv3d(128, 128, 3, padding = 'same')\n",
        "        self.conv13 = nn.Conv3d(128, 128, 3, padding = 'same') # could go to 256/512 somewhere here\n",
        "        self.conv14 = nn.Conv3d(128, 128, 3, padding = 'same')\n",
        "        self.conv15 = nn.Conv3d(128, 256, 3, padding = 'same')\n",
        "        self.conv16 = nn.Conv3d(256, 256, 3, padding = 'same')\n",
        "        self.conv17 = nn.Conv3d(256, 256, 3, padding = 'same')\n",
        "        self.conv18 = nn.Conv3d(256, 256, 3, padding = 'same')\n",
        "        self.conv19 = nn.Conv3d(256, 256, 3, padding = 'same')\n",
        "        self.conv20 = nn.Conv3d(256, 256, 3, padding = 'same')\n",
        "        self.conv21 = nn.Conv3d(256, 256, 3, padding = 'same')\n",
        "        self.conv22 = nn.Conv3d(256, 256, 3, padding = 'same')\n",
        "\n",
        "        self.pool1 = nn.MaxPool3d((1, 2, 2))\n",
        "        self.pool2 = nn.MaxPool3d(2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.preds1 = nn.Linear(int(256*(frames/2)*(size/64)*(size/64)), num_words)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #C T H W = 3 self.frames self.size self.size\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        tmp = x\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.relu(self.conv4(x))\n",
        "        x = tmp + x\n",
        "        x = self.pool1(self.relu(self.conv5(x))) # 64 self.frames self.size/2 self.size/2\n",
        "        tmp = x\n",
        "        x = self.relu(self.conv6(x))\n",
        "        x = self.relu(self.conv7(x))\n",
        "        x = tmp + x \n",
        "        x = self.relu(self.conv8(x))\n",
        "        tmp = x \n",
        "        x = self.relu(self.conv9(x))\n",
        "        x = self.relu(self.conv10(x)) \n",
        "        x = tmp + x \n",
        "        x = self.pool1(x) # C T H W = 128 self.frames self.size/4 self.size/4\n",
        "        tmp = x\n",
        "        x = self.relu(self.conv11(x))\n",
        "        x = self.relu(self.conv12(x))\n",
        "        x = tmp + x\n",
        "        x = self.pool1(x) # 128 self.frames self.size/8 self.size/8\n",
        "        tmp = x\n",
        "        x = self.relu(self.conv13(x)) \n",
        "        x = self.relu(self.conv14(x)) \n",
        "        x = tmp + x\n",
        "        x = self.pool1(self.relu(self.conv15(x))) #256 self.frames self.size/16 self.size/16\n",
        "        tmp = x\n",
        "        x = self.relu(self.conv16(x)) \n",
        "        x = self.relu(self.conv17(x)) \n",
        "        x = tmp + x \n",
        "        x = self.pool1(x) # 256 self.frames self.size/32 self.size/32\n",
        "        tmp = x\n",
        "        x = self.relu(self.conv18(x)) \n",
        "        x = self.relu(self.conv19(x))\n",
        "        x = tmp + x\n",
        "        x = self.pool2(x) # 256 sel.frames/2 self.size/64 self.size/64\n",
        "        tmp = x\n",
        "        x = self.relu(self.conv20(x)) \n",
        "        x = self.relu(self.conv21(x))\n",
        "        x = tmp + x\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = self.relu(self.preds1(x))\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OZIAw798vDYW"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(1, 3, 60, 256, 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pRb-3kgrvooZ"
      },
      "outputs": [],
      "source": [
        "model = Net()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "E103uNnUvvr8",
        "outputId": "7b5b0a69-0f6f-4e67-edae-4b25c2972492"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2.9595e-02, 2.0553e-02, 1.9745e-02, 4.6181e-02, 0.0000e+00, 1.8215e-02,\n",
              "         1.0659e-02, 2.6596e-02, 2.7734e-03, 0.0000e+00, 1.0990e-02, 2.8617e-02,\n",
              "         0.0000e+00, 1.3510e-03, 0.0000e+00, 0.0000e+00, 5.6103e-02, 9.4475e-03,\n",
              "         2.8532e-02, 0.0000e+00, 2.6057e-02, 0.0000e+00, 1.3344e-02, 0.0000e+00,\n",
              "         6.8253e-03, 5.2664e-03, 0.0000e+00, 4.9352e-03, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5034e-04, 2.3408e-02, 0.0000e+00,\n",
              "         5.9795e-02, 0.0000e+00, 1.8474e-02, 9.9461e-03, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 2.8883e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         2.4072e-02, 4.3061e-03, 0.0000e+00, 1.8086e-02, 0.0000e+00, 0.0000e+00,\n",
              "         5.3076e-04, 1.8341e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9735e-02,\n",
              "         1.0951e-02, 0.0000e+00, 1.1297e-03, 0.0000e+00, 2.6014e-03, 1.2794e-02,\n",
              "         1.3548e-02, 0.0000e+00, 3.7915e-03, 0.0000e+00, 0.0000e+00, 1.7471e-02,\n",
              "         1.2329e-02, 7.3701e-03, 4.6237e-02, 2.7740e-04, 3.2330e-02, 9.1924e-03,\n",
              "         0.0000e+00, 1.5761e-02, 0.0000e+00, 2.3099e-02, 5.0884e-03, 1.1484e-02,\n",
              "         2.9609e-02, 0.0000e+00, 3.5705e-03, 0.0000e+00, 5.4033e-04, 1.9179e-02,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6480e-02, 2.1884e-02, 1.3484e-02,\n",
              "         2.0096e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2768e-03, 0.0000e+00,\n",
              "         1.5902e-03, 1.0889e-02, 0.0000e+00, 5.0063e-03, 0.0000e+00, 0.0000e+00,\n",
              "         2.8557e-02, 3.3240e-02, 8.4745e-03, 1.2606e-02, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 3.0018e-02, 0.0000e+00, 2.4613e-02, 1.2255e-02, 1.7877e-02,\n",
              "         1.0727e-02, 0.0000e+00, 0.0000e+00, 6.3522e-03, 2.0178e-03, 2.6271e-02,\n",
              "         1.8675e-02, 0.0000e+00, 2.9916e-03, 0.0000e+00, 0.0000e+00, 2.0366e-02,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5431e-03, 0.0000e+00, 2.0946e-02,\n",
              "         0.0000e+00, 0.0000e+00, 1.6559e-02, 1.3673e-02, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 9.5727e-03, 0.0000e+00, 2.5841e-02, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 1.0883e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 8.6263e-03, 3.9728e-02, 0.0000e+00, 4.7463e-04, 8.4083e-03,\n",
              "         2.3298e-02, 1.1938e-02, 0.0000e+00, 3.8366e-02, 0.0000e+00, 3.1588e-02,\n",
              "         1.9383e-02, 1.6910e-02, 0.0000e+00, 7.1385e-03, 3.0286e-02, 1.1414e-02,\n",
              "         1.9932e-02, 0.0000e+00, 0.0000e+00, 3.4035e-02, 2.1947e-02, 0.0000e+00,\n",
              "         1.2906e-02, 1.6449e-02, 1.5151e-02, 3.6442e-02, 1.3270e-02, 1.7119e-02,\n",
              "         0.0000e+00, 1.6072e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7779e-03,\n",
              "         0.0000e+00, 8.5165e-03, 3.4588e-03, 0.0000e+00, 2.7865e-02, 1.2347e-02,\n",
              "         0.0000e+00, 1.4597e-02, 1.9690e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         5.8808e-03, 2.3669e-02, 0.0000e+00, 1.3160e-02, 4.2480e-02, 4.4332e-03,\n",
              "         0.0000e+00, 4.9832e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5078e-02,\n",
              "         1.6713e-02, 1.6313e-02, 1.9317e-02, 1.7673e-02, 0.0000e+00, 2.0260e-02,\n",
              "         3.0449e-02, 9.0033e-03, 0.0000e+00, 2.7847e-02, 0.0000e+00, 0.0000e+00,\n",
              "         8.5598e-03, 2.3105e-02, 0.0000e+00, 2.5394e-02, 0.0000e+00, 0.0000e+00,\n",
              "         2.3119e-02, 1.0666e-02, 2.3139e-02, 3.7797e-02, 0.0000e+00, 3.6172e-02,\n",
              "         0.0000e+00, 1.8552e-02, 0.0000e+00, 3.6101e-03, 1.6925e-02, 1.8259e-02,\n",
              "         0.0000e+00, 1.5429e-03, 5.2544e-03, 2.3634e-02, 0.0000e+00, 0.0000e+00,\n",
              "         1.7150e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7444e-03,\n",
              "         2.2411e-02, 4.1794e-03, 0.0000e+00, 5.1050e-02, 2.6346e-02, 0.0000e+00,\n",
              "         0.0000e+00, 4.6319e-03, 2.2296e-02, 1.0034e-02, 0.0000e+00, 1.7524e-02,\n",
              "         0.0000e+00, 3.0428e-02, 1.1270e-02, 9.7399e-03, 3.4765e-02, 2.7761e-02,\n",
              "         1.6358e-02, 0.0000e+00, 2.1372e-05, 1.3230e-02, 1.5543e-02, 0.0000e+00,\n",
              "         0.0000e+00, 3.0350e-02, 0.0000e+00, 0.0000e+00, 2.8243e-02, 2.3232e-04,\n",
              "         0.0000e+00, 1.0984e-02, 1.7262e-03, 0.0000e+00, 0.0000e+00, 5.6481e-02,\n",
              "         5.6925e-03, 0.0000e+00, 0.0000e+00, 2.2115e-02, 0.0000e+00, 1.4685e-02,\n",
              "         3.1214e-02, 1.3015e-02, 0.0000e+00, 2.8912e-02, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 1.1054e-02, 0.0000e+00, 1.6523e-02, 1.5924e-02, 0.0000e+00,\n",
              "         0.0000e+00, 3.7567e-03, 0.0000e+00, 1.0559e-02, 0.0000e+00, 2.8286e-02,\n",
              "         0.0000e+00, 2.2008e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 1.5155e-02, 2.0052e-02, 3.4205e-02, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 2.8899e-03, 3.3325e-02, 2.5800e-02, 0.0000e+00, 1.7868e-03,\n",
              "         0.0000e+00, 1.7215e-02, 0.0000e+00, 3.6700e-02]],\n",
              "       grad_fn=<ReluBackward0>)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1     [-1, 32, 60, 256, 256]           2,624\n",
            "              ReLU-2     [-1, 32, 60, 256, 256]               0\n",
            "            Conv3d-3     [-1, 32, 60, 256, 256]          27,680\n",
            "              ReLU-4     [-1, 32, 60, 256, 256]               0\n",
            "            Conv3d-5     [-1, 32, 60, 256, 256]          27,680\n",
            "              ReLU-6     [-1, 32, 60, 256, 256]               0\n",
            "            Conv3d-7     [-1, 32, 60, 256, 256]          27,680\n",
            "              ReLU-8     [-1, 32, 60, 256, 256]               0\n",
            "            Conv3d-9     [-1, 64, 60, 256, 256]          55,360\n",
            "             ReLU-10     [-1, 64, 60, 256, 256]               0\n",
            "        MaxPool3d-11     [-1, 64, 60, 128, 128]               0\n",
            "           Conv3d-12     [-1, 64, 60, 128, 128]         110,656\n",
            "             ReLU-13     [-1, 64, 60, 128, 128]               0\n",
            "           Conv3d-14     [-1, 64, 60, 128, 128]         110,656\n",
            "             ReLU-15     [-1, 64, 60, 128, 128]               0\n",
            "           Conv3d-16    [-1, 128, 60, 128, 128]         221,312\n",
            "             ReLU-17    [-1, 128, 60, 128, 128]               0\n",
            "           Conv3d-18    [-1, 128, 60, 128, 128]         442,496\n",
            "             ReLU-19    [-1, 128, 60, 128, 128]               0\n",
            "           Conv3d-20    [-1, 128, 60, 128, 128]         442,496\n",
            "             ReLU-21    [-1, 128, 60, 128, 128]               0\n",
            "        MaxPool3d-22      [-1, 128, 60, 64, 64]               0\n",
            "           Conv3d-23      [-1, 128, 60, 64, 64]         442,496\n",
            "             ReLU-24      [-1, 128, 60, 64, 64]               0\n",
            "           Conv3d-25      [-1, 128, 60, 64, 64]         442,496\n",
            "             ReLU-26      [-1, 128, 60, 64, 64]               0\n",
            "        MaxPool3d-27      [-1, 128, 60, 32, 32]               0\n",
            "           Conv3d-28      [-1, 128, 60, 32, 32]         442,496\n",
            "             ReLU-29      [-1, 128, 60, 32, 32]               0\n",
            "           Conv3d-30      [-1, 128, 60, 32, 32]         442,496\n",
            "             ReLU-31      [-1, 128, 60, 32, 32]               0\n",
            "           Conv3d-32      [-1, 256, 60, 32, 32]         884,992\n",
            "             ReLU-33      [-1, 256, 60, 32, 32]               0\n",
            "        MaxPool3d-34      [-1, 256, 60, 16, 16]               0\n",
            "           Conv3d-35      [-1, 256, 60, 16, 16]       1,769,728\n",
            "             ReLU-36      [-1, 256, 60, 16, 16]               0\n",
            "           Conv3d-37      [-1, 256, 60, 16, 16]       1,769,728\n",
            "             ReLU-38      [-1, 256, 60, 16, 16]               0\n",
            "        MaxPool3d-39        [-1, 256, 60, 8, 8]               0\n",
            "           Conv3d-40        [-1, 256, 60, 8, 8]       1,769,728\n",
            "             ReLU-41        [-1, 256, 60, 8, 8]               0\n",
            "           Conv3d-42        [-1, 256, 60, 8, 8]       1,769,728\n",
            "             ReLU-43        [-1, 256, 60, 8, 8]               0\n",
            "        MaxPool3d-44        [-1, 256, 30, 4, 4]               0\n",
            "           Conv3d-45        [-1, 256, 30, 4, 4]       1,769,728\n",
            "             ReLU-46        [-1, 256, 30, 4, 4]               0\n",
            "           Conv3d-47        [-1, 256, 30, 4, 4]       1,769,728\n",
            "             ReLU-48        [-1, 256, 30, 4, 4]               0\n",
            "           Linear-49                  [-1, 340]      41,779,540\n",
            "             ReLU-50                  [-1, 340]               0\n",
            "================================================================\n",
            "Total params: 56,521,524\n",
            "Trainable params: 56,521,524\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 45.00\n",
            "Forward/backward pass size (MB): 11155.81\n",
            "Params size (MB): 215.61\n",
            "Estimated Total Size (MB): 11416.42\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\khota\\miniconda3\\envs\\test\\lib\\site-packages\\torchsummary\\torchsummary.py:93: RuntimeWarning: overflow encountered in long_scalars\n",
            "  total_output += np.prod(summary[layer][\"output_shape\"])\n"
          ]
        }
      ],
      "source": [
        "#Parameters\n",
        "from torchsummary import summary\n",
        "summary(model, (3, 60, 256, 256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Training Loop Below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'trainloader' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\khota\\OneDrive\\Documents\\GitHub\\Group6-SP22\\Research\\AKMyModelAndTraining.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000008?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m):  \u001b[39m# loop over the dataset multiple times\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000008?line=1'>2</a>\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m trainloader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000008?line=2'>3</a>\u001b[0m         \u001b[39m# get the inputs; data is a list of [inputs, labels]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000008?line=3'>4</a>\u001b[0m         inputs, labels \u001b[39m=\u001b[39m data\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khota/OneDrive/Documents/GitHub/Group6-SP22/Research/AKMyModelAndTraining.ipynb#ch0000008?line=5'>6</a>\u001b[0m         \u001b[39m# zero the parameter gradients\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'trainloader' is not defined"
          ]
        }
      ],
      "source": [
        "for epoch in range(50):  # loop over the dataset multiple times\n",
        "    for data in trainloader:\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "print('Finished Training')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CS124H.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
